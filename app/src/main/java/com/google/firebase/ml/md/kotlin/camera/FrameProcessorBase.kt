/*
 * Copyright 2019 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     https://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package com.google.firebase.ml.md.kotlin.camera

import android.os.SystemClock
import android.util.Log
import androidx.annotation.GuardedBy
import com.google.android.gms.tasks.Task
import com.google.firebase.ml.vision.common.FirebaseVisionImage
import com.google.firebase.ml.vision.common.FirebaseVisionImageMetadata
import java.nio.ByteBuffer

/** Abstract base class of [FrameProcessor].  */
abstract class FrameProcessorBase<T> : FrameProcessor {

    // To keep the latest frame and its metadata.
    @GuardedBy("this")
    private var latestFrame: ByteArray? = null

    @GuardedBy("this")
    private var latestFrameMetaData: FrameMetadata? = null

    // To keep the frame and metadata in process.
    @GuardedBy("this")
    private var processingFrame: ByteArray? = null

    @GuardedBy("this")
    private var processingFrameMetaData: FrameMetadata? = null

    @Synchronized
    override fun process(
        data: ByteArray, frameMetadata: FrameMetadata, graphicOverlay: GraphicOverlay) {
        latestFrame = data
        latestFrameMetaData = frameMetadata
        if (processingFrame == null && processingFrameMetaData == null) {
            processLatestFrame(graphicOverlay)
        }
    }

    @Synchronized
    private fun processLatestFrame(graphicOverlay: GraphicOverlay) {
        processingFrame = latestFrame
        processingFrameMetaData = latestFrameMetaData
        latestFrame = null
        latestFrameMetaData = null
        val frame = processingFrame ?: return
        val frameMetaData = processingFrameMetaData ?: return
        val metadata = FirebaseVisionImageMetadata.Builder()
            .setFormat(FirebaseVisionImageMetadata.IMAGE_FORMAT_NV21)
            .setWidth(frameMetaData.width)
            .setHeight(frameMetaData.height)
            .setRotation(frameMetaData.rotation)
            .build()
        val image = FirebaseVisionImage.fromByteArray(frame, metadata)
        val startMs = SystemClock.elapsedRealtime()

        //TODO: WHat happens here?
        detectInImage(image)
            .addOnSuccessListener { results ->
                Log.d(TAG, "Latency is: " + (SystemClock.elapsedRealtime() - startMs))
                this@FrameProcessorBase.onSuccess(image, results, graphicOverlay)
                processLatestFrame(graphicOverlay)
            }
            .addOnFailureListener { this@FrameProcessorBase.onFailure(it) }
    }

    protected abstract fun detectInImage(image: FirebaseVisionImage): Task<T>

    /** Be called when the detection succeeds.  */
    protected abstract fun onSuccess(
        image: FirebaseVisionImage, results: T, graphicOverlay: GraphicOverlay
    )

    protected abstract fun onFailure(e: Exception)

    companion object {
        private const val TAG = "FrameProcessorBase"
    }
}
